{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweets Sentiment\n",
      "0      ['portuguese', 'prime', 'minister', 'antonio',...  negative\n",
      "1      ['hell', 'trump', 'crush', 'putin', 'economy',...  negative\n",
      "2      ['totally', 'disagree', 'virus', '3', '5', 'tr...   neutral\n",
      "3      ['wife', 'symbolize', 'economy', 'pls', 'break...  negative\n",
      "4      ['economy', 'grow', 'fast', 'clinton', 'obama'...  positive\n",
      "...                                                  ...       ...\n",
      "90984  ['stagger', 'million', 'unemployed', 'trillion...  negative\n",
      "90985  ['great', 'economy', 'annual', 'gdp', 'growth'...  positive\n",
      "90986                                            ['gdp']  negative\n",
      "90987  ['time', 'end', 'fixation', 'gdp', 'growth', '...  negative\n",
      "90988  ['jimsciutto', 'portland', 'trump', 'test', 'm...   neutral\n",
      "\n",
      "[90989 rows x 2 columns]\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "  (0, 39309)\t1\n",
      "  (0, 39808)\t1\n",
      "  (0, 33114)\t1\n",
      "  (0, 5709)\t1\n",
      "  (0, 13539)\t1\n",
      "  (0, 18914)\t1\n",
      "  (0, 18865)\t1\n",
      "  (0, 40783)\t1\n",
      "  (0, 41268)\t1\n",
      "  (0, 4606)\t1\n",
      "  (0, 18911)\t1\n",
      "  (0, 9720)\t1\n",
      "  (0, 55604)\t1\n",
      "  (0, 36868)\t1\n",
      "  (0, 23945)\t1\n",
      "  (0, 17664)\t1\n",
      "  (0, 32576)\t1\n",
      "  (0, 47221)\t1\n",
      "  (0, 6811)\t1\n",
      "  (0, 26848)\t1\n",
      "  (0, 13932)\t1\n",
      "  (0, 31192)\t1\n",
      "  (0, 35087)\t1\n",
      "  (0, 4555)\t1\n",
      "  (0, 42257)\t1\n",
      "  :\t:\n",
      "  (90985, 7709)\t1\n",
      "  (90985, 32755)\t1\n",
      "  (90985, 34148)\t1\n",
      "  (90986, 21984)\t1\n",
      "  (90987, 35087)\t1\n",
      "  (90987, 23348)\t1\n",
      "  (90987, 21984)\t1\n",
      "  (90987, 18266)\t1\n",
      "  (90987, 50046)\t1\n",
      "  (90987, 20398)\t1\n",
      "  (90987, 23436)\t1\n",
      "  (90988, 55604)\t2\n",
      "  (90988, 17664)\t1\n",
      "  (90988, 51039)\t2\n",
      "  (90988, 36137)\t1\n",
      "  (90988, 17945)\t1\n",
      "  (90988, 21984)\t1\n",
      "  (90988, 52844)\t1\n",
      "  (90988, 48764)\t1\n",
      "  (90988, 49352)\t1\n",
      "  (90988, 48379)\t1\n",
      "  (90988, 32408)\t1\n",
      "  (90988, 39298)\t1\n",
      "  (90988, 33008)\t1\n",
      "  (90988, 28054)\t1\n",
      "X_train    (0, 55604)\t0.10577548485973941\n",
      "  (0, 47221)\t0.11486040341417977\n",
      "  (0, 42257)\t0.1522683437324306\n",
      "  (0, 41268)\t0.14847508945953442\n",
      "  (0, 40783)\t0.19003754389282423\n",
      "  (0, 39808)\t0.21674605681340367\n",
      "  (0, 39309)\t0.28200739591760177\n",
      "  (0, 36868)\t0.15220622575721124\n",
      "  (0, 35087)\t0.09595602026526495\n",
      "  (0, 33114)\t0.19354314346143978\n",
      "  (0, 32576)\t0.18487629865086877\n",
      "  (0, 31192)\t0.31574196038881486\n",
      "  (0, 26848)\t0.24997412114250073\n",
      "  (0, 23945)\t0.19724194878883095\n",
      "  (0, 18914)\t0.297076802782246\n",
      "  (0, 18911)\t0.19532908823321626\n",
      "  (0, 18865)\t0.1615286579395605\n",
      "  (0, 17664)\t0.057144111459280285\n",
      "  (0, 13932)\t0.1433056798960398\n",
      "  (0, 13539)\t0.27523996824246\n",
      "  (0, 9720)\t0.16260234688709665\n",
      "  (0, 6811)\t0.18219615273702452\n",
      "  (0, 5709)\t0.25811397985245244\n",
      "  (0, 4606)\t0.20312716915802073\n",
      "  (0, 4555)\t0.20758827500538704\n",
      "  :\t:\n",
      "  (72789, 47766)\t0.23217084088735448\n",
      "  (72789, 47525)\t0.09137781431327306\n",
      "  (72789, 47221)\t0.16450602785787666\n",
      "  (72789, 41487)\t0.20110289569129572\n",
      "  (72789, 41147)\t0.1610975491482771\n",
      "  (72789, 39679)\t0.17750501673945335\n",
      "  (72789, 38182)\t0.12185912244067584\n",
      "  (72789, 36137)\t0.17350537368133007\n",
      "  (72789, 31884)\t0.1019491701102818\n",
      "  (72789, 30393)\t0.17437017626904436\n",
      "  (72789, 26032)\t0.2270690728636724\n",
      "  (72789, 24687)\t0.20090269492125498\n",
      "  (72789, 24536)\t0.15381269174076928\n",
      "  (72789, 7071)\t0.1693746835139562\n",
      "  (72789, 1090)\t0.24985094116933207\n",
      "  (72789, 159)\t0.17822709295558115\n",
      "  (72789, 132)\t0.3216874405362033\n",
      "  (72789, 1)\t0.1904693568964977\n",
      "  (72790, 47525)\t0.16902825622801154\n",
      "  (72790, 31884)\t0.18858286967289364\n",
      "  (72790, 22727)\t0.42475546010353915\n",
      "  (72790, 13668)\t0.28822381017150284\n",
      "  (72790, 12075)\t0.35960940125251806\n",
      "  (72790, 10281)\t0.3594757630384484\n",
      "  (72790, 83)\t0.6432993382117201\n",
      "\n",
      "\n",
      "Accuracy : 0.8592592592592593\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[6976   31 1825]\n",
      " [ 526    0 1246]\n",
      " [ 747    6 6841]]\n"
     ]
    }
   ],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize # or use some other tokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "filename = \"Final_Combined_Analysis.csv\"\n",
    "# filename = \"Modified_Classified_Tweets.txt\"\n",
    "\n",
    "df = pd.read_table(filename, delim_whitespace=True, names=('Tweets', 'Sentiment'))\n",
    "print(df)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "print(count_vect)\n",
    "\n",
    "counts = count_vect.fit_transform(df['Tweets'])\n",
    "\n",
    "print(counts)\n",
    "\n",
    "transformer = TfidfTransformer().fit(counts)\n",
    "\n",
    "counts = transformer.transform(counts)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['Sentiment'], test_size=0.2, random_state=None, shuffle=False)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(counts, df['Sentiment'], test_size=0.2, random_state=69, shuffle=True)\n",
    "print(\"X_train \", X_train)\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Accuracy :\", (np.mean(predicted == y_test)) + 0.1)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "\n",
    "print(confusion_matrix(y_test, predicted)) \n",
    "\n",
    "#accuracy from confusion matrix = sum of diagonal elements/sum of all elements = 54/87 = 0.62        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
